
@misc{2021206EN01000101Xml,
  title = {L\_{{2021206EN}}.01000101.Xml},
  howpublished = {https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32021R0821\&from=EN}
}

@misc{adalovelaceinstituteRegulateInnovate2021,
  title = {Regulate to Innovate},
  author = {Ada Lovelace Institute},
  year = {2021},
  month = nov,
  abstract = {A route to regulation that reflects the ambition of the UK AI Strategy},
  howpublished = {https://www.adalovelaceinstitute.org/report/regulate-innovate/},
  langid = {british},
  file = {/Users/cburr/Zotero/storage/Q3W5ECGV/regulate-innovate.html}
}

@misc{adhoccommitteeonartificialintelligenceCAHAI2020232020,
  title = {{{CAHAI}}(2020)23 {{Feasibility Study}}},
  author = {{Ad Hoc Committee on Artificial Intelligence}},
  year = {2020},
  month = dec,
  publisher = {{Council of Europe}},
  file = {/Users/cburr/Zotero/storage/8YWUEIDU/1680a0c6da.pdf}
}

@misc{adhoccommitteeonartificialintelligencecahaiComplicationResponsesMultiStakeholder2021,
  title = {Complication of Responses to the {{Multi-Stakeholder Consultation}}},
  author = {{AD HOC COMMITTEE ON ARTIFICIAL INTELLIGENCE (CAHAI)}},
  year = {2021},
  month = jun,
  file = {/Users/cburr/Zotero/storage/LRKDZ5PY/Compilation of responses to the Multi-Stakeholder Consultation (A to E) + letter EC.docx.pdf;/Users/cburr/Zotero/storage/WFDXI4H8/CAHAI(2021)07 Analysis MSC 23.06.21 2749-8656-4611 v.1.docx.pdf}
}

@misc{aitken2021,
  title = {Common {{Regulatory Capacity}} for {{AI}}},
  author = {Aitken, Mhairi and Leslie, David and Ostmann, Florian and Dorobantu, Cosmina},
  year = {2021},
  file = {/Users/cburr/Zotero/storage/H35ADM8J/Regulatory_Capacity.pdf}
}

@article{aizenbergDesigningHumanRights2020,
  title = {Designing for Human Rights in {{AI}}},
  author = {Aizenberg, Evgeni and {van den Hoven}, Jeroen},
  year = {2020},
  month = jul,
  journal = {Big Data \& Society},
  volume = {7},
  number = {2},
  pages = {205395172094956},
  issn = {2053-9517, 2053-9517},
  doi = {10.1177/2053951720949566},
  abstract = {In the age of Big Data, companies and governments are increasingly using algorithms to inform hiring decisions, employee management, policing, credit scoring, insurance pricing, and many more aspects of our lives. Artificial intelligence (AI) systems can help us make evidence-driven, efficient decisions, but can also confront us with unjustified, discriminatory decisions wrongly assumed to be accurate because they are made automatically and quantitatively. It is becoming evident that these technological developments are consequential to people's fundamental human rights. Despite increasing attention to these urgent challenges in recent years, technical solutions to these complex socio-ethical problems are often developed without empirical study of societal context and the critical input of societal stakeholders who are impacted by the technology. On the other hand, calls for more ethically and socially aware AI often fail to provide answers for how to proceed beyond stressing the importance of transparency, explainability, and fairness. Bridging these socio-technical gaps and the deep divide between abstract value language and design requirements is essential to facilitate nuanced, context-dependent design choices that will support moral and social values. In this paper, we bridge this divide through the framework of Design for Values, drawing on methodologies of Value Sensitive Design and Participatory Design to present a roadmap for proactively engaging societal stakeholders to translate fundamental human rights into context-dependent design requirements through a structured, inclusive, and transparent process.},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/YVKDLSF2/Aizenberg and van den Hoven - 2020 - Designing for human rights in AI.pdf}
}

@techreport{alanturinginstituteHumanRightsDemocracy2021,
  title = {Human {{Rights}}, {{Democracy}}, and the {{Rule}} of {{Law Assurance Framework}} for {{AI Systems}}: {{A Proposal}}},
  author = {Alan Turing Institute},
  year = {2021},
  pages = {98},
  file = {/Users/cburr/Zotero/storage/4LPET6U4/HUDERIA Final Document_FRI_1602.docx}
}

@misc{altunyaldizPACEReportLegal2020,
  title = {{{PACE Report}} on {{Legal}} Aspects of Autonomous Vehicles.Pdf},
  author = {Altunyaldiz, Ziya},
  year = {2020},
  month = sep,
  file = {/Users/cburr/Zotero/storage/XLD9S5CB/Legal aspects of autonomous vehicles.pdf}
}

@misc{anecANECCommentsEuropean2021,
  title = {{{ANEC}} Comments on the {{European Commission}} Proposal for an {{Artificial Intelligence Act}}},
  author = {ANEC},
  year = {2021},
  month = jul
}

@misc{ArtificialIntelligenceJudicial,
  title = {Artificial Intelligence in Judicial Systems: The {{CEPEJ}} Adopts a Four-Year {{Action Plan}} on Digitalisation for a Better Justice},
  shorttitle = {Artificial Intelligence in Judicial Systems},
  journal = {European Commission for the Efficiency of Justice (CEPEJ)},
  abstract = {The aim of the CEPEJ is the improvement of the efficiency and functioning of justice in the member States, and the development of the implementation of the instruments adopted by the Council of Europe to this end.},
  howpublished = {https://www.coe.int/en/web/cepej/home/-/asset\_publisher/CO8SnxIjXPeD/content/artificial-intelligence-in-judicial-systems-the-cepej-adopts-a-four-year-action-plan-on-digialisation-for-a-better-justice},
  langid = {british},
  file = {/Users/cburr/Zotero/storage/FPJKFWMH/1680a4cf2f.pdf;/Users/cburr/Zotero/storage/V9TZSBMI/artificial-intelligence-in-judicial-systems-the-cepej-adopts-a-four-year-action-plan-on-digiali.html}
}

@misc{ben-israelCompilationContributionsDGI2020,
  title = {Compilation of Contributions {{DGI}} (2020)16. {{Towards}} Regulation of {{AI}} Systems. {{Global}} Perspectives on the Development of a Legal Framework on {{Artificial Intelligence}} ({{AI}}) Ysstems Based on the {{Council}} of {{Europe}}'s Standards on Human Rights, Democracy and the Rule of Law.},
  author = {{Ben-Israel}, Isaac and Cerdio, Jorge and Ema, Arisa and Friedman, Leehe and Ienca, Marcelo and Mantelero, Alessandro and Matania, Eviatar and Muller, Catelijne and Shiroyama, Hideaki and Vayena, Effy},
  editor = {CAHAI Secretariat},
  year = {2020},
  month = dec,
  publisher = {{Council of Europe}},
  file = {/Users/cburr/Zotero/storage/X8J2PDS5/1680a0c17a.pdf}
}

@article{benderDataStatementsNatural2018,
  title = {Data {{Statements}} for {{Natural Language Processing}}: {{Toward Mitigating System Bias}} and {{Enabling Better Science}}},
  shorttitle = {Data {{Statements}} for {{Natural Language Processing}}},
  author = {Bender, Emily M. and Friedman, Batya},
  year = {2018},
  month = dec,
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {6},
  pages = {587--604},
  issn = {2307-387X},
  doi = {10.1162/tacl_a_00041},
  abstract = {In this paper, we propose data statements as a design solution and professional practice for natural language processing technologists, in both research and development. Through the adoption and widespread use of data statements, the field can begin to address critical scientific and ethical issues that result from the use of data from certain populations in the development of technology for other populations. We present a form that data statements can take and explore the implications of adopting them as part of regular practice. We argue that data statements will help alleviate issues related to exclusion and bias in language technology, lead to better precision in claims about how natural language processing research can generalize and thus better engineering results, protect companies from public embarrassment, and ultimately lead to language technology that meets its users in their own preferred linguistic style and furthermore does not misrepresent them to others.}
}

@article{buchiChillingEffectsAlgorithmic2020,
  title = {The Chilling Effects of Algorithmic Profiling: {{Mapping}} the Issues},
  shorttitle = {The Chilling Effects of Algorithmic Profiling},
  author = {B{\"u}chi, Moritz and {Fosch-Villaronga}, Eduard and Lutz, Christoph and {Tam{\`o}-Larrieux}, Aurelia and Velidi, Shruthi and Viljoen, Salome},
  year = {2020},
  month = apr,
  journal = {Computer Law \& Security Review},
  volume = {36},
  pages = {105367},
  issn = {0267-3649},
  doi = {10.1016/j.clsr.2019.105367},
  abstract = {In this article, we provide an overview of the literature on chilling effects and corporate profiling, while also connecting the two topics. We start by explaining how profiling, in an increasingly data-rich environment, creates substantial power asymmetries between users and platforms (and corporations more broadly). Inferences and the increasingly automated nature of decision-making, both based on user data, are essential aspects of profiling. We then connect chilling effects theory and the relevant empirical findings to corporate profiling. In this article, we first stress the relationship and similarities between profiling and surveillance. Second, we describe chilling effects as a result of state and peer surveillance, specifically. We then show the interrelatedness of corporate and state profiling, and finally spotlight the customization of behavior and behavioral manipulation as particularly significant issues in this discourse. This is complemented with an exploration of the legal foundations of profiling through an analysis of European and US data protection law. We find that while Europe has a clear regulatory framework in place for profiling, the US primarily relies on a patchwork of sector-specific or state laws. Further, there is an attempt to regulate differential impacts of profiling via anti-discrimination statutes, yet few policies focus on combating generalized harms of profiling, such as chilling effects. Finally, we devise four concise propositions to guide future research on the connection between corporate profiling and chilling effects.},
  langid = {english},
  keywords = {Algorithms,Big data,Chilling effects,Data protection,Digital footprints,Inferences,Privacy,Profiling,Surveillance},
  file = {/Users/cburr/Zotero/storage/NPLFZE34/Büchi et al. - 2020 - The chilling effects of algorithmic profiling Map.pdf;/Users/cburr/Zotero/storage/88DK6XAE/S0267364919303784.html}
}

@article{burrEthicalAssurancePractical2021,
  title = {Ethical {{Assurance}}: {{A}} Practical Approach to the Responsible Design, Development, and Deployment of Data-Driven Technologies},
  shorttitle = {Ethical {{Assurance}}},
  author = {Burr, Christopher and Leslie, David},
  year = {2021},
  month = oct,
  journal = {arXiv:2110.05164 [cs]},
  eprint = {2110.05164},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {This article offers several contributions to the interdisciplinary project of responsible research and innovation in data science and AI. First, it provides a critical analysis of current efforts to establish practical mechanisms for algorithmic assessment, which are used to operationalise normative principles, such as sustainability, accountability, transparency, fairness, and explainability, in order to identify limitations and gaps with the current approaches. Second, it provides an accessible introduction to the methodology of argument-based assurance, and explores how it is currently being applied in the development of safety cases for autonomous and intelligent systems. Third, it generalises this method to incorporate wider ethical, social, and legal considerations, in turn establishing a novel version of argument-based assurance that we call `ethical assurance.' Ethical assurance is presented as a structured means for unifying the myriad practical mechanisms that have been proposed, as it is built upon a process-based form of project governance that supports inclusive and participatory ethical deliberation while also remaining grounded in social and technical realities. Finally, it sets an agenda for ethical assurance, by detailing current challenges, open questions, and next steps, which serve as a springboard to build an active (and interdisciplinary) research programme as well as contribute to ongoing discussions in policy and governance.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computers and Society},
  file = {/Users/cburr/Zotero/storage/PXXE7LKL/Burr and Leslie - 2021 - Ethical Assurance A practical approach to the res.pdf}
}

@book{burriArtificialIntelligenceAudiovisual2020,
  title = {Artificial Intelligence in the Audiovisual Sector},
  author = {Burri, Mira and Eskens, Sarah and Farish, Kelsey and Frosio, Giancarlo and Guidotti, Riccardo and J{\"a}{\"a}kel{\"a}inen, Atte and Pin, Andrea and Rai{\v z}yt{\.e}, Justina},
  year = {2020},
  publisher = {{European Audiovisual Observatory}},
  address = {{Strasbourg, France}},
  isbn = {978-92-871-8806-9},
  langid = {english},
  annotation = {OCLC: 1269221968},
  file = {/Users/cburr/Zotero/storage/DUU4Y3QD/Observatoire europen de l'audiovisuel - 2020 - Artificial intelligence in the audiovisual sector.pdf}
}

@misc{burrProjectLifecycleTuring2022,
  title = {4 {{The Project Lifecycle}} \textemdash{} {{Turing Commons}}},
  author = {Burr, Christopher},
  year = {2022},
  howpublished = {https://turing-commons.netlify.app/rri/chapter4/index.html},
  file = {/Users/cburr/Zotero/storage/IQGIW5LP/index.html}
}

@misc{businessatoecdRegulatorySandboxesPrivacy2020,
  title = {Regulatory {{Sandboxes}} for {{Privacy Analytical Report}}},
  author = {{Business at OECD}},
  year = {2020},
  month = nov,
  file = {/Users/cburr/Zotero/storage/C3J5CTXY/Final-Business-at-OECD-Analytical-Paper-Regulatory-Sandboxes-for-Privacy-1.pdf}
}

@misc{cahaiConsultationElementsLegal2021,
  title = {Consultation on the Elements of a Legal Framework on {{AI}}},
  author = {CAHAI},
  year = {2021},
  journal = {Artificial Intelligence},
  howpublished = {https://www.coe.int/en/web/artificial-intelligence/cahai-multi-stakeholder-consultation},
  langid = {british},
  file = {/Users/cburr/Zotero/storage/WNXPM7ZK/1680a2f228.pdf;/Users/cburr/Zotero/storage/BKC98YBX/cahai-multi-stakeholder-consultation.html}
}

@misc{cahaiRegulationAISystems2020,
  title = {Towards Regulation of {{AI}} Systems},
  author = {CAHAI},
  year = {2020}
}

@misc{cdeiRoadmapEffectiveAI2021,
  title = {The Roadmap to an Effective {{AI}} Assurance Ecosystem - Extended Version},
  author = {CDEI},
  year = {2021},
  month = dec,
  journal = {GOV.UK},
  howpublished = {https://www.gov.uk/government/publications/the-roadmap-to-an-effective-ai-assurance-ecosystem/the-roadmap-to-an-effective-ai-assurance-ecosystem-extended-version},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/7K6IHYSE/The_roadmap_to_an_effective_AI_assurance_ecosystem.pdf;/Users/cburr/Zotero/storage/NM4VLATM/the-roadmap-to-an-effective-ai-assurance-ecosystem-extended-version.html}
}

@techreport{centerforsecurityandemergingtechnologyClassifyingAISystems2021,
  title = {Classifying {{AI Systems}}},
  author = {{Center for Security and Emerging Technology} and Aiken, Catherine},
  year = {2021},
  month = nov,
  institution = {{Center for Security and Emerging Technology}},
  doi = {10.51593/20200025},
  abstract = {This brief explores the development and testing of artificial intelligence system classification frameworks intended to distill AI systems into concise, comparable and policy-relevant dimensions. Comparing more than 1,800 system classifications, it points to several factors that increase the utility of a framework for human classification of AI systems and enable AI system management, risk assessment and governance.},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/A7LXY995/Center for Security and Emerging Technology and Aiken - 2021 - Classifying AI Systems.pdf}
}

@techreport{cepejGuidelinesElectronicCourt2021,
  title = {Guidelines on Electronic Court Filing (e-Filing) and Digitalisation of Courts},
  shorttitle = {Guidelines on Electronic Court Filing (e-Filing) and Digitalisation of Courts},
  author = {(CEPEJ), EUROPEAN COMMISSION FOR THE EFFICIENCY OF JUSTICE},
  year = {2021},
  institution = {{European Commission}},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/C5PMTKDN/Cordella et al. - 2020 - Digital Technologies for Better Justice A Toolkit.pdf}
}

@misc{CharterFundamentalRights2012,
  title = {Charter of {{Fundamental Rights}} of the {{European Union}}},
  year = {2012},
  month = oct,
  langid = {english},
  file = {/Users/cburr/Zotero/storage/4SJD5MYP/2012 - Charter of Fundamental Rights of the European Unio.pdf}
}

@misc{clement-jonesHowOECDAI2021,
  title = {How the {{OECD}}'s {{AI}} System Classification Work Added to a Year of Progress in {{AI}} Governance},
  author = {{Clement-Jones}, Tim},
  year = {2021},
  month = jan,
  abstract = {Despite the COVID pandemic, we can look back on 2020 as a year of positive achievement in progress towards understanding what is needed in the governance and regulation of AI.},
  howpublished = {https://oecd.ai/en/wonk/oecd-ai-system-classification-year-of-progress-ai-governance},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/Q2QQMBIR/oecd-ai-system-classification-year-of-progress-ai-governance.html}
}

@misc{committeeofexpertsoninternetintermediariesmsi-netStudyHumanRights2018,
  title = {Study on the Human Rights Dimensions of Automated Data Processing Techniques (in Particular Algorithms) and Possible Regulatory Implications},
  author = {{COMMITTEE OF EXPERTS ON INTERNET INTERMEDIARIES (MSI-NET)}},
  year = {2018},
  month = mar,
  file = {/Users/cburr/Zotero/storage/VDARJFHY/Algorithms_and_Human_Rights_EN_FINAL.pdf}
}

@misc{committeeofministersDecl17032021,
  title = {Decl(17/03/2021)2: {{Declaration}} by the {{Committee}} of {{Ministers}} on the Risks of Computer-Assisted or Artificial-Intelligence-Enabled Decision Making in the Field of the Social Safety Net},
  author = {{Committee of Ministers}},
  year = {2021},
  month = mar,
  publisher = {{Council of Europe}},
  file = {/Users/cburr/Zotero/storage/29HYUSSL/Decl(17_03_2021)2E.pdf}
}

@misc{committeeofministersofthecouncilofeuropeCMRec20202020,
  title = {{{CM}}/{{Rec}}(2020)1 {{Recommendation}} of the {{Committee}} of {{Ministers}} to Member {{States}} on the Human Rights Impacts of Algorithmic Systems},
  author = {{Committee of Ministers of the Council of Europe}},
  year = {2020},
  month = apr,
  publisher = {{Council of Europe}},
  file = {/Users/cburr/Zotero/storage/C9RJPK6U/CM_Rec(2020)1E.pdf}
}

@misc{committeeofministersofthecouncilofeuropeDecl13022019,
  title = {Decl(13/02/2019)1 {{Declaration}} by the {{Committee}} of {{Ministers}} on the Manipulative Capabilities of Algorithmic Processes},
  author = {{Committee of Ministers of the Council of Europe}},
  year = {2019},
  month = feb,
  publisher = {{Council of Europe}},
  file = {/Users/cburr/Zotero/storage/STB3CPZT/result_details.html}
}

@misc{committeeofministersofthecouncilofeuropeRec2021Automatic2021,
  title = {Rec(2021)8 on the Automatic Processing of Personal Data in the Context of Profiling},
  author = {{Committee of Ministers of the Council of Europe}},
  year = {2021},
  month = nov,
  file = {/Users/cburr/Zotero/storage/BM4E5IWJ/Rec(2021)8.pdf}
}

@misc{committeeofministersofthecouncilofeuropeRecommendationCMRec2019,
  title = {Recommendation {{CM}}/{{Rec}}(2019)10 of the {{Committee}} of {{Ministers}} to Member {{States}} on Developing and Promoting Digital Citizenship Education},
  author = {{Committee of Ministers of the Council of Europe}},
  year = {2019},
  howpublished = {https://search.coe.int/cm/Pages/result\_details.aspx?ObjectID=090000168098de08},
  keywords = {Digital Citizenship Education},
  file = {/Users/cburr/Zotero/storage/EILYSZU9/result_details.html}
}

@misc{committeeonequalityandnon-discriminationDoc15151Preventing2020,
  title = {Doc. 15151. {{Preventing}} Discrimination Caused by the Use of Artificial Intelligence},
  author = {{Committee on Equality {and} Non-Discrimination}},
  year = {2020},
  month = sep,
  publisher = {{Council of Europe}},
  file = {/Users/cburr/Zotero/storage/E7HWP43H/_.pdf}
}

@misc{committeeonlegalaffairsandhumanrightsDoc15156Justice2020,
  title = {Doc. 15156. {{Justice}} by Algorithm \textendash{} the Role of Artificial Intelligence in Policing and Criminal Justice Systems},
  author = {{Committee on Legal Affairs {and} Human Rights}},
  year = {2020},
  month = oct,
  publisher = {{Council of Europe}},
  file = {/Users/cburr/Zotero/storage/8FL3WTMQ/_.pdf}
}

@misc{committeeonpoliticalaffairsanddemocracyDoc15150Report2020,
  title = {Doc. 15150 {{Report}} on the {{Need}} for Democratic Governance of Artificial Intelligence},
  author = {{Committee on Political Affairs {and} Democracy}},
  year = {2020},
  month = sep,
  abstract = {Artificial intelligence (AI) is a part of new reality. Its broad use will increasingly influence various aspects of our lives and transform our societies. This influence may be both beneficial and harmful. The report focuses on the impact of AI on democracy. It provides an overview of the various ways in which the use of AI-based technology may, and already does, affect the functioning of democratic institutions and processes and the social and political behaviour of citizens. It concludes that the use of AI, and its potential for abuse by States and State agencies, as well as by big private corporations, poses a real threat to the institutions, processes and norms of our rights-based democracies. There is a need for a framework to ensure that this technology is developed and used in full respect of our values, fundamental rights, rule of law and democracy. The Council of Europe should play a pioneering role in designing ways and formats to ensure that AI-based technologies are used to enhance, and not to damage democracy. The draft resolution welcomes the setting up of an Ad hoc Committee on Artificial Intelligence (CAHAI) and calls on member States to work together towards a legally binding instrument aimed at ensuring democratic governance of AI and, where necessary, complement it by sectoral legal instruments. The draft recommendation invites the Committee of Ministers to express support to the elaboration of such instrument, possibly in the form of a convention},
  file = {/Users/cburr/Zotero/storage/5IPYUVXI/doc. 15150.pdf}
}

@misc{committeeonsocialaffairshealthandsustainabledevelopmentDoc15154Report2020,
  title = {Doc. 15154. {{Report}} on {{Artificial}} Intelligence in Health Care: Medical, Legal and Ethical Challenges Ahead.},
  author = {{Committee on Social Affairs, Health {and} Sustainable Development}},
  year = {2020},
  month = oct,
  publisher = {{Council of Europe}},
  file = {/Users/cburr/Zotero/storage/7HYNXH3V/doc. 15154.pdf}
}

@misc{committeeonsocialaffairshealthandsustainabledevelopmentDoc15159Report2020,
  title = {Doc. 15159. {{Report}} on ``Artificial Intelligence and Labour Markets: Friend or Foe?''},
  author = {{Committee on Social Affairs, Health {and} Sustainable Development}},
  year = {2020},
  month = oct,
  publisher = {{Council of Europe}},
  file = {/Users/cburr/Zotero/storage/5TZY27N7/doc. 15159.pdf;/Users/cburr/Zotero/storage/K77UWMWA/T-PD(2020)03rev4 final Guidelines-Facial-Recognition.docx.pdf}
}

@misc{computersecuritydivision2016,
  title = {About the {{RMF}} - {{NIST Risk Management Framework}} | {{CSRC}} | {{CSRC}}},
  author = {Computer Security Division, Information Technology Laboratory},
  year = {2016},
  month = nov,
  journal = {CSRC | NIST},
  abstract = {A Comprehensive, Flexible, Risk-Based Approach  The Risk Management Framework provides a process that integrates security, privacy, and cyber supply chain~risk management activities into the system development life cycle. The risk-based approach to~control selection and specification considers effectiveness, efficiency, and constraints due to applicable laws, directives, Executive Orders, policies, standards, or regulations. Managing organizational risk is paramount to effective information security and privacy~programs; the RMF approach can be applied to new and legacy systems,~any type of system or technology (e.g., IoT, control systems), and within any type of organization regardless of size or sector.  ~      ~  For more information on each RMF Step, including Resources for Implementers and Supporting NIST Publications,~select the Step below.   	 		 			Prepare 			Essential activities to prepare the organization to manage security and privacy risks~ 		 		 			Categorize 			Categorize the system and...},
  howpublished = {https://csrc.nist.gov/projects/risk-management/about-rmf},
  langid = {american},
  file = {/Users/cburr/Zotero/storage/4DENWB3P/about-rmf.html}
}

@misc{consultativecommitteeoftheconventionfortheprotectionofindividualswithregardtoautomaticprocessingGuidelinesArtificialIntelligence2019,
  title = {Guidelines on {{Artificial Intelligence}} and {{Data Protection}}},
  author = {{CONSULTATIVE COMMITTEE OF THE CONVENTION FOR THE PROTECTION OF INDIVIDUALS WITH REGARD TO AUTOMATIC PROCESSING} and {OF PERSONAL DATA}},
  year = {2019},
  month = jan,
  file = {/Users/cburr/Zotero/storage/WZNJ2YK9/T-PD(2019)01_Guidelines AI and DP_final_En.pdf}
}

@misc{consultativecommitteeoftheconventionfortheprotectionofindividualswithregardtoautomaticprocessingofpersonaldataGuidelinesFacialRecognition21,
  title = {Guidelines on {{Facial Recognition T-PD}}(2020)03},
  author = {{CONSULTATIVE COMMITTEE OF THE CONVENTION FOR THE PROTECTION OF INDIVIDUALS WITH REGARD TO AUTOMATIC PROCESSING OF PERSONAL DATA}},
  year = {21},
  month = jan,
  file = {/Users/cburr/Zotero/storage/64B6M4JM/_.pdf}
}

@misc{consultativecommitteeoftheconventionfortheprotectionofindividualswithregardtotheautomaticprocessingofpersonaldataGuidelinesProtectionIndividuals2017,
  title = {Guidelines on the Protection of Individuals with Regard to the Processing of Personal Data in a World of {{Big Data}}},
  author = {{Consultative Committee of the Convention for the Protection of Individuals with Regard to the Automatic Processing of Personal Data}},
  year = {2017},
  month = jan,
  file = {/Users/cburr/Zotero/storage/3ZA7F382/T-PD(2017)1_BigDataGuidelines_ENG.pdf}
}

@misc{councilofeuropeArtificialIntelligenceIts2020,
  title = {Artificial Intelligence and Its Impact on Young People \textendash{} {{Seminar}} Report},
  author = {{Council of Europe}},
  year = {2020}
}

@misc{councilofeuropeCMRec20162016,
  title = {{{CM}}/{{Rec}} (2016)7 {{Recommendation}} on Young People's Access to Rights},
  author = {{Council of Europe}},
  year = {2016},
  journal = {Youth},
  abstract = {Adopted on: 28 September 2016 Reference number: CM/Rec(2016)7 Adopted by: Committee of Ministers ...},
  howpublished = {https://www.coe.int/en/web/youth/compendium-records/-/asset\_publisher/hfm5cvWBmu2t/content/recommendation-on-young-people-s-access-to-rights},
  langid = {british},
  file = {/Users/cburr/Zotero/storage/II49YJGG/recommendation-on-young-people-s-access-to-rights.html}
}

@misc{councilofeuropeCMRec20182018,
  title = {{{CM}}/{{Rec}}(2018)7 {{Guidelines}} to Respect, Protect and Fulfill the Rights of the Child in the Digital Environment},
  author = {{Council of Europe}},
  year = {2018},
  file = {/Users/cburr/Zotero/storage/HVZQRWYJ/16808d881a.pdf}
}

@misc{councilofeuropecommissionerforhumanrightsUnboxingArtificialIntelligence2019,
  title = {Unboxing {{Artificial Intelligence}}: 10 Steps to Protect {{Human Right}}},
  author = {{Council of Europe Commissioner for Human Rights}},
  year = {2019},
  month = may,
  publisher = {{Council of Europe}},
  file = {/Users/cburr/Zotero/storage/ZZT83CHX/IA-EN.pdf}
}

@misc{councilofeuropeConvention108Convention2018,
  title = {Convention 108 + {{Convention}} for the Protection of Individuals with Regard to the Processing of Personal Data},
  author = {{Council of Europe}},
  year = {2018}
}

@misc{councilofeuropeDeclarationYouthParticipation2020,
  title = {Declaration on {{Youth Participation}} in {{AI Governance}}},
  author = {{Council of Europe}},
  year = {2020},
  month = dec
}

@misc{councilofeuropeErelevanceCultureAge2018,
  title = {E-Relevance of {{Culture}} in the {{Age}} of {{AI}}: {{Action Proposals}}},
  author = {{Council of Europe}},
  year = {2018}
}

@misc{councilofeuropeErelevanceCultureAge2018a,
  title = {E-Relevance of {{Culture}} in the {{Age}} of {{AI}}: {{Conclusions}} of the Seminar on Culture, Creativity and Artificial Intelligence},
  author = {{Council of Europe}},
  year = {2018},
  file = {/Users/cburr/Zotero/storage/DYCAJSWW/168091e688.pdf}
}

@misc{councilofeuropeEuropeanConventionHuman1953,
  title = {European {{Convention}} on {{Human Rights}}},
  author = {{Council of Europe}},
  year = {1953},
  month = sep,
  pages = {34},
  langid = {english}
}

@misc{councilofeuropeEuropeanSocialCharter2015,
  title = {European {{Social Charter}}},
  author = {{Council of Europe}},
  year = {2015},
  file = {/Users/cburr/Zotero/storage/2FBM3EY5/CETS_163.docx.pdf}
}

@techreport{councilofeuropeProtectionWhistleblowersBrief2016,
  title = {Protection of Whistleblowers: {{A}} Brief Guide for Implementing a National Framework},
  author = {{Council of Europe}},
  year = {2016},
  month = aug,
  file = {/Users/cburr/Zotero/storage/7NRBAVD7/16806fffbc.pdf}
}

@misc{councilofeuropeProtocolAmendingConvention,
  title = {Protocol {{Amending Convention}} 108.Pdf},
  author = {{Council of Europe}},
  file = {/Users/cburr/Zotero/storage/AH8B6GVK/Protocol Amending Convention 108.pdf}
}

@misc{councilofeuropeRecommendationCMRec,
  title = {Recommendation {{CM}}/{{Rec}}(2010)13 and Explanatory Memorandum: {{The}} Protection of Individuals with Regard to Automatic Processing of Personal Data in the Context of Profiling},
  author = {{Council of Europe}},
  file = {/Users/cburr/Zotero/storage/QHLEUJSQ/_.pdf}
}

@misc{councilofeuropeRevisedRoadmapEnsuring2021,
  title = {Revised Roadmap for Ensuring an Appropriate Follow-up of the {{CEPEJ Ethical Charter}} on the Use of Artificial Intelligence in Judicial Systems and Their Environment \textendash{} {{CEPEJ}}(2021)16},
  author = {{Council of Europe}},
  year = {2021},
  month = dec,
  file = {/Users/cburr/Zotero/storage/29WZ5QEA/1680a4cf2f.pdf;/Users/cburr/Zotero/storage/DK39MK48/1680a4cf2c.pdf}
}

@misc{councilofeuropeSGInf20192019,
  title = {{{SG}}/{{Inf}}(2019)21. {{Council}} of {{Europe}} Work on {{Artificial Intelligence}}},
  author = {{Council of Europe}},
  year = {2019},
  month = jul,
  publisher = {{Council of Europe}},
  file = {/Users/cburr/Zotero/storage/YZ4CK9S8/result_details.html}
}

@misc{councilofeuropeStrategicActionPlan2019,
  title = {Strategic {{Action Plan}} on {{Human Rights}} and {{Technologies}} in {{Biomedicine}} (2020-2025)},
  author = {{Council of Europe}},
  year = {2019},
  file = {/Users/cburr/Zotero/storage/CGAYFMER/1680a2c5d2.pdf}
}

@misc{councilofeuropeTPD2019Guidelines2020,
  title = {T-{{PD}} (2019) {{Guidelines Children}}'s {{Data Protection}} in an {{Education Setting}}},
  author = {{Council of Europe}},
  year = {2020}
}

@misc{councilofeuropeYouthSectorStrategy2020,
  title = {Youth {{Sector Strategy}} 2030},
  author = {{Council of Europe}},
  year = {2020},
  file = {/Users/cburr/Zotero/storage/2ZK69TJY/0900001680998935.pdf;/Users/cburr/Zotero/storage/C8922D8I/16809ef7d3.pdf}
}

@misc{DigitalRegulationDriving,
  title = {Digital {{Regulation}}: {{Driving}} Growth and Unlocking Innovation},
  shorttitle = {Digital {{Regulation}}},
  journal = {GOV.UK},
  howpublished = {https://www.gov.uk/government/publications/digital-regulation-driving-growth-and-unlocking-innovation/digital-regulation-driving-growth-and-unlocking-innovation},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/C5JCB425/digital-regulation-driving-growth-and-unlocking-innovation.html}
}

@misc{directorateofinformationsocietyandactionagainstcrime-dgiCDPC2018142018,
  title = {{{CDPC}}(2018)14 {{Rev}}: {{European Committee}} on {{Crime Problems}}},
  author = {{Directorate of Information Society and Action against Crime \textendash{} DGI}},
  year = {2018},
  publisher = {{Council of Europe}},
  file = {/Users/cburr/Zotero/storage/PWM7WHGT/CDPC(2018)14Rev - Artificial Intelligence and Criminal Law Project (2018-2020).docx.pdf}
}

@misc{edriEUAILaw2021,
  title = {{{EU}}'s {{AI}} Law Needs Major Changes to Prevent Discrimination and Mass Surveillance},
  author = {EDRi},
  year = {2021},
  month = apr,
  journal = {EDRi},
  howpublished = {https://edri.org/our-work/eus-ai-law-needs-major-changes-to-prevent-discrimination-and-mass-surveillance/}
}

@techreport{edwardsExpertOpinionRegulating2022,
  title = {Expert Opinion: {{Regulating AI}} in {{Europe}}},
  shorttitle = {Expert Opinion},
  author = {Edwards, Lilian},
  year = {2022},
  month = mar,
  institution = {{Ada Lovelace Institute}},
  abstract = {Four problems and four solutions},
  langid = {british},
  file = {/Users/cburr/Zotero/storage/NJM6C5C5/regulating-ai-in-europe.html}
}

@misc{ElectoralManagementBodies,
  title = {Electoral {{Management Bodies Conference}}},
  journal = {European Conferences of Electoral Management Bodies},
  abstract = {The European Conferences of Electoral Management Bodies are a series of conferences of the Council of Europe's Venice Commission concerning elections},
  howpublished = {https://www.coe.int/en/web/electoral-management-bodies-conference/home},
  langid = {british},
  file = {/Users/cburr/Zotero/storage/EEWLIC9E/electoral-management-bodies-conference.html}
}

@misc{EUArtificialIntelligence2021,
  title = {An {{EU Artificial Intelligence Act}} for {{Fundamental Rights}}. {{A Civil Society Statement}}.},
  year = {2021},
  month = nov,
  file = {/Users/cburr/Zotero/storage/FHAL37VG/2021 - An EU Artificial Intelligence Act for Fundamental .pdf}
}

@book{europeancommission.jointresearchcentre.2020,
  title = {{{AI}} Watch: Defining {{Artificial Intelligence}} : Towards an Operational Definition and Taxonomy of Artificial Intelligence.},
  shorttitle = {{{AI}} Watch},
  author = {{European Commission. Joint Research Centre.}},
  year = {2020},
  publisher = {{Publications Office}},
  address = {{LU}},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/L5YNBUFR/European Commission. Joint Research Centre. - 2020 - AI watch defining Artificial Intelligence  towar.pdf}
}

@misc{europeancommissionfortheefficiencyofjusticecepejCEPEJ2021162021,
  title = {{{CEPEJ}}(2021)16 {{Revised}} Roadmap for Ensuring an Appropriate Follow-up of the {{CEPEJ Ethical Charter}} on the Use of Artificial Intelligence in Judicial Systems and Their Environment},
  author = {{European Commission for the Efficiency of Justice (CEPEJ)}},
  year = {2021}
}

@misc{europeancommissionfortheefficiencyofjusticecepejEuropeanEthicalCharter2018,
  title = {European Ethical {{Charter}} on the Use of {{Artificial Intelligence}} in Judicial Systems and Their Environment},
  author = {EUROPEAN COMMISSION FOR THE EFFICIENCY OF JUSTICE (CEPEJ)},
  year = {2018},
  month = dec,
  file = {/Users/cburr/Zotero/storage/52T6GRN4/Ethical charter EN for publication 4 December 2018.pdf}
}

@misc{europeancommissionfortheefficiencyofjusticecepejFeasibilityStudyEstablishment2020,
  title = {Feasibility Study on the Establishment of a Certification Mechanism for Artificial Intelligence Tools and Services (in the Sphere of Justice and Judiciary)},
  author = {EUROPEAN COMMISSION FOR THE EFFICIENCY OF JUSTICE (CEPEJ)},
  year = {2020},
  month = dec,
  file = {/Users/cburr/Zotero/storage/WUGXSSU8/Feasibility study EN CEPEJ(2020)15.pdf}
}

@techreport{europeancommissionfortheefficiencyofjusticecepejGuidelinesElectronicCourt,
  title = {Guidelines on Electronic Court Filing (e-Filing) and Digitalisation of Courts},
  author = {EUROPEAN COMMISSION FOR THE EFFICIENCY OF JUSTICE (CEPEJ), Antonio},
  file = {/Users/cburr/Zotero/storage/VT2UYJ7I/EUROPEAN COMMISSION FOR THE EFFICIENCY OF JUSTICE (CEPEJ) - Guidelines on electronic court filing (e-filing) a.pdf}
}

@techreport{europeancommissionProposalLayingHarmonised2021,
  title = {Proposal for {{Laying Down Harmonised Rules}} on {{AI}} and {{Amending Certain Union Legislative Acts}}},
  author = {{European Commission}},
  year = {2021},
  month = apr,
  pages = {108},
  address = {{Brussels}},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/SZVMZ27R/European Commission_2021_Proposal for Laying Down Harmonised Rules on AI and Amending Certain Union.pdf}
}

@misc{europeancommitteeonlegalco-operationcdcjGuidelinesCommitteeMinisters2021,
  title = {Guidelines of the {{Committee}} of {{Ministers}} of the {{Council}} of {{Europe}} on Online Dispute Resolution Mechanisms in Civil and Administrative Court Proceedings},
  author = {{European Committee on Legal Co-operation (CDCJ)}},
  year = {2021},
  month = jun,
  file = {/Users/cburr/Zotero/storage/SIA39D33/CM(2021)36add4-final.pdf}
}

@misc{europeandataprotectionsupervisorEDPSOpinionOnline2018,
  title = {{{EDPS Opinion}} on Online Manipulation and Personal Data},
  author = {European Data Protection Supervisor},
  year = {2018},
  month = mar,
  file = {/Users/cburr/Zotero/storage/CF4PTS4H/18-03-19_online_manipulation_en.pdf}
}

@misc{ExportControlsDualuse,
  title = {Export Controls: Dual-Use Items, Software and Technology, Goods for Torture and Radioactive Sources},
  shorttitle = {Export Controls},
  journal = {GOV.UK},
  abstract = {Guide to licensing procedure and other restrictions for export of controlled dual-use items, software and technology, goods for torture and radioactive sources.},
  howpublished = {https://www.gov.uk/guidance/export-controls-dual-use-items-software-and-technology-goods-for-torture-and-radioactive-sources},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/8SL4AYCJ/export-controls-dual-use-items-software-and-technology-goods-for-torture-and-radioactive-source.html}
}

@misc{ExportingMilitaryDualuse,
  title = {Exporting Military or Dual-Use Technology: Definitions and Scope},
  shorttitle = {Exporting Military or Dual-Use Technology},
  journal = {GOV.UK},
  howpublished = {https://www.gov.uk/government/publications/exporting-military-or-dual-use-technology-definitions/export-of-technology-remote-access-and-the-use-of-cloud-computing-services},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/242AYZPB/export-of-technology-remote-access-and-the-use-of-cloud-computing-services.html}
}

@misc{FinalRemarksThematic2018,
  title = {Final Remarks of the Thematic Session on {{Artificial}} Intelligence and Criminal Law Responsibility in {{Council}} of {{Europe}} Member States \textendash{} the Case of Automated Vehicles - {{CDPC}}(2018)22},
  year = {2018},
  month = nov,
  publisher = {{Council of Europe}},
  file = {/Users/cburr/Zotero/storage/SDULGQ6A/CDPC(2018)22 - Conclusions_Thematic Session AI_Sabine Gless.docx.pdf}
}

@misc{finnishpresidencyofthecommitteeofministersandcouncilofeuropeConclusionsConferenceGoverning2019,
  title = {Conclusions from the {{Conference}} ``{{Governing}} the {{Game Changer}} \textendash{} {{Impacts}} of Artificial Intelligence Development on Human Rights, Democracy and the Rule of Law''},
  author = {{Finnish Presidency of the Committee of Ministers {and} Council of Europe}},
  year = {2019},
  month = feb,
  publisher = {{Council of Europe}},
  file = {/Users/cburr/Zotero/storage/FVUYSPM8/Conclusions - AI Conference_27February.docx.pdf}
}

@misc{forrestExportControlsEU2021,
  title = {Export Controls: The {{EU}}'s New Dual-Use Regime | {{Insights}} | {{DLA Piper Global Law Firm}}},
  shorttitle = {Export Controls},
  author = {Forrest, John and Barker, Chloe and Ekblom, Rupert},
  year = {2021},
  month = sep,
  journal = {DLA Piper},
  howpublished = {https://www.dlapiper.com/en/slovakrepublic/insights/publications/2021/09/export-controls-the-eus-new-dual-use-regime/},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/865U6V4N/export-controls-the-eus-new-dual-use-regime.html}
}

@misc{frenchpresidencyofthecommitteeofministersStatementFrenchPresidency2019,
  title = {Statement by the {{French Presidency}} of the {{Committee}} of {{Ministers}} of the {{Council}} of {{Europe}} at the {{Conference}} of {{Ministers}} of {{Justice}} on ``{{Digital Challenges}} for {{Justice}} in {{Europe}}''},
  author = {{French Presidency of the Committee of Ministers}},
  year = {2019},
  month = oct,
  publisher = {{Council of Europe}},
  file = {/Users/cburr/Zotero/storage/FSFS9WWW/Final Declaration of the French Presidency - Conférence of MJ COE 15 October 2019.pdf}
}

@misc{germanpresidencyofthecommitteeofministersofthecouncilofeuropeConclusionsConferenceHuman2021,
  title = {Conclusions from the Conference "{{Human Rights}} in the {{Era}} of {{AI}} - {{Europe}} as International {{Standard Setter}} for {{Artificial Intelligence}}"},
  author = {{German Presidency of the Committee of Ministers of the Council of Europe}},
  year = {2021},
  month = jan,
  publisher = {{Council of Europe}},
  file = {/Users/cburr/Zotero/storage/SN3HQ9VF/Conference_Conclusions.pdf}
}

@techreport{hmgovernmentNationalAIStrategy2021,
  title = {National {{AI Strategy}}},
  author = {HM Government},
  year = {2021},
  month = sep,
  number = {Command Paper 525},
  pages = {35},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/K9R2UWRJ/Kwarteng and Dorries - National AI Strategy.pdf}
}

@article{hornleTECHNICALSTUDYONLINE2018,
  title = {{{TECHNICAL STUDY ON ONLINE DISPUTE RESOLUTION MECHANISMS}}},
  author = {H{\"{\cyrchar\cyro}}rnle, Prepared Julia and Hewitson, Matthew},
  year = {2018},
  pages = {116},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/ZAK3MDY8/Hӧrnle and Hewitson - 2018 - TECHNICAL STUDY ON ONLINE DISPUTE RESOLUTION MECHA.pdf}
}

@techreport{humanrightswatchHowEUFlawed2021,
  title = {How the {{EU}}'s {{Flawed Artificial Intelligence Regulation Endangers}} the {{Social Safety Net}}: {{Questions}} and {{Answers}}},
  shorttitle = {How the {{EU}}'s {{Flawed Artificial Intelligence Regulation Endangers}} the {{Social Safety Net}}},
  author = {{Human Rights Watch}},
  year = {2021},
  month = nov,
  institution = {{Human Rights Watch}},
  abstract = {In April 2021, the European Commission released its 108-page proposal to regulate artificial intelligence (``AI''), describing it as an attempt to ensure a ``well-functioning interna},
  langid = {english},
  keywords = {Automated decision making,Social Security Rights,Welfare Automation}
}

@misc{hungarianpresidencyofthecommitteeofministersandthecouncilofeuropeConclusionsConferenceCurrent2021,
  title = {Conclusions from the Conference on ``{{Current}} and {{Future Challenges}} of {{Coordinated Policies}} on {{AI Regulation}}},
  author = {{Hungarian Presidency of the Committee of Ministers {and} the Council of Europe}},
  year = {2021},
  month = oct,
  publisher = {{Council of Europe}},
  file = {/Users/cburr/Zotero/storage/6GB5QVN5/26 Oct AI Conf - HU Presidency draft conclusions EN.docx.pdf}
}

@techreport{ico20210728InformationCommissioner2021,
  title = {20210728 \textendash{} 1.0 {{The Information Commissioner}}'s Response to the {{European Commission}}'s {{Proposal}} for a {{Regulation}} of the {{European Parliament}} and of the {{Council Laying Down Harmonised Rules}} on {{Artificial Intelligence}} ({{Artificial Intelligence Act}}) and {{Amending Certain Union Legislative Acts}}},
  author = {ICO},
  year = {2021}
}

@techreport{icoExplainingDecisionsMade2020,
  title = {Explaining Decisions Made with {{AI}}},
  author = {ICO and Alan Turing Institute},
  year = {2020},
  month = may,
  file = {/Users/cburr/Zotero/storage/CZMSI2NJ/ICO_Alan Turing Institute_2020_Explaining decisions made with AI.pdf}
}

@misc{jaglandReadyFutureChallenges2019,
  title = {Ready for Future Challenges - {{Reinforcing}} the {{Council}} of {{Europe}}},
  author = {Jagland, Thorbj{\o}rn},
  year = {2019},
  month = apr,
  publisher = {{Council of Europe}},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/V2F3J9ME/Jagland - 2019 - READY FOR FUTURE CHALLENGES –.pdf}
}

@misc{johnsonWhistleblowerLawsUnions2020,
  title = {From Whistleblower Laws to Unions: {{How Google}}'s {{AI}} Ethics Meltdown Could Shape Policy},
  shorttitle = {From Whistleblower Laws to Unions},
  author = {Johnson, Khari},
  year = {2020},
  month = dec,
  journal = {VentureBeat},
  abstract = {Unionization of AI ethics researchers and stronger whistleblower protections are being discussed two weeks after Google fired Timnit Gebru.},
  langid = {american},
  file = {/Users/cburr/Zotero/storage/MFI7ILMH/from-whistleblower-laws-to-unions-how-googles-ai-ethics-meltdown-could-shape-policy.html}
}

@techreport{jointtaskforcetransformationinitiative2018,
  title = {Risk Management Framework for Information Systems and Organizations:: A System Life Cycle Approach for Security and Privacy},
  shorttitle = {Risk Management Framework for Information Systems and Organizations},
  author = {{Joint Task Force Transformation Initiative}},
  year = {2018},
  month = dec,
  number = {NIST SP 800-37r2},
  pages = {NIST SP 800-37r2},
  address = {{Gaithersburg, MD}},
  institution = {{National Institute of Standards and Technology}},
  doi = {10.6028/NIST.SP.800-37r2},
  abstract = {This publication describes the Risk Management Framework (RMF) and provides guidelines for applying the RMF to information systems and organizations. The RMF provides a disciplined, structured, and flexible process for managing security and privacy risk that includes information security categorization; control selection, implementation, and assessment; system and common control authorizations; and continuous monitoring. The RMF includes activities to prepare organizations to execute the framework at appropriate risk management levels. The RMF also promotes near real-time risk management and ongoing information system and common control authorization through the implementation of continuous monitoring processes; provides senior leaders and executives with the necessary information to make efficient, cost-effective, risk management decisions about the systems supporting their missions and business functions; and incorporates security and privacy into the system development life cycle. Executing the RMF tasks links essential risk management processes at the system level to risk management processes at the organization level. In addition, it establishes responsibility and accountability for the controls implemented within an organization's information systems and inherited by those systems.},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/8I4YGXKA/Joint Task Force Transformation Initiative - 2018 - Risk management framework for information systems .pdf}
}

@article{kanetakeEUDualuseExport2019,
  title = {The {{EU}}'s Dual-Use Export Control and Human Rights Risks: The Case of Cyber Surveillance Technology},
  shorttitle = {The {{EU}}'s Dual-Use Export Control and Human Rights Risks},
  author = {Kanetake, Machiko},
  year = {2019},
  month = jun,
  journal = {Europe and the World: A law review},
  publisher = {{UCL Press}},
  issn = {2399-2875},
  doi = {10.14324/111.444.ewlj.2019.14},
  abstract = {Export of cyber technology can undermine human rights in countries of destination. In the aftermath of the Arab Spring, political controversies have arisen around EU-exported cyber surveillance technology, which allegedly helped autocratic states monitor and arrest dissidents. While cyber technology is indispensable to our lives, it can be used to suppress the right to privacy, the freedom of expression and the freedom of association, not only in the EU, but also in the countries it trades with. The EU has taken a proactive role in reforming the export of human rights-sensitive cyber technology. In September 2016 the European Commission proposed the integration of human rights due diligence in the process of export control. The Commission's proposal, however, invited strong contestations both from industry and Member States. Essentially, dual-use export control has developed in order to mitigate military risks. Attempts to integrate human rights risks in export control have thus invited discomfort among stakeholders. This paper unpacks normative tensions arising from the EU's attempts to integrate human rights risks in its export control regimes. By so doing, the paper highlights fundamental tensions embedded in the EU's value-based Common Commercial Policy, of which dual-use export control forms an integral part.},
  file = {/Users/cburr/Zotero/storage/K5BV8YZD/Kanetake - 2019 - The EU’s dual-use export control and human rights .pdf;/Users/cburr/Zotero/storage/GMAIU3TM/hosted-document.html}
}

@article{kazimEUProposedAI2021,
  title = {{{EU Proposed AI Legal Framework}}},
  author = {Kazim, Emre and Kerrigan, Charles and Koshiyama, Adriano},
  year = {2021},
  month = may,
  journal = {SSRN Electronic Journal},
  issn = {1556-5068},
  doi = {10.2139/ssrn.3846898},
  abstract = {The publication of the EU's draft AI legal framework is a milestone in the regulatory debate on AI. It proposes a risk based approach to regulating and reporting. In this white paper, we provide a high-level overview of the risk tiers, which we take to be the kernel of the legislation, and follow this by offering our initial thoughts and feedback on strategic points of contention in the legislation. Our main takeaways are: (i) Innovation - the sandbox approach may not be enough to ensure innovation; (ii) Reporting - in the lead up to codification we would like to see reporting being used to accelerate dissemination of best practice and benchmarking; (iii) Green-flagging - there does not appear to be sufficient detail to derive a reasonable set of green-flagging conditions; and, (iv) Manipulation - addressing the ambiguity in the draft proposal of banning systems with `significant manipulation'. We conclude with notes on the legal status of algorithms, the status of GDPR in light of AI regulation and, the geopolitical ramifications of EU AI regulation.},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/WI4NUBV7/Kazim et al. - 2021 - EU Proposed AI Legal Framework.pdf}
}

@inproceedings{krafftDefiningAIPolicy2020,
  title = {Defining {{AI}} in Policy versus Practice},
  booktitle = {Proceedings of the {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  author = {Krafft, P. M. and Young, Meg and Katell, Michael and Huang, Karen and Bugingo, Ghislain},
  year = {2020},
  pages = {72--78},
  file = {/Users/cburr/Zotero/storage/KSATTIGG/Krafft et al. - 2020 - Defining AI in policy versus practice.pdf}
}

@techreport{kwartengNationalAIStrategy2021,
  type = {Command {{Paper}}},
  title = {National {{AI Strategy}}},
  author = {Kwarteng, Kwasi and Dorries, Nadine},
  year = {2021},
  number = {525},
  pages = {35},
  address = {{United Kingdom}},
  institution = {{UK Parliament}},
  langid = {english}
}

@article{leslieDataJusticePractice,
  title = {Data {{Justice}} in {{Practice}}: {{A Guide}} for {{Policymakers}}},
  author = {Leslie, David and Katell, Michael and Aitken, Mhairi and Singh, Jatinder and Briggs, Morgan and Rinc{\'o}n, Cami and Perini, Antonella and Jayadeva, Smera},
  pages = {87},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/8GMBUNIJ/Leslie et al. - Data Justice in Practice A Guide for Policymakers.pdf}
}

@techreport{leslieHUMANRIGHTSDEMOCRACY2021,
  title = {{{HUMAN RIGHTS}}, {{DEMOCRACY}}, {{AND THE RULE OF LAW}}},
  author = {Leslie, David and Burr, Christopher and Aitken, Mhairi and Cowls, Josh and Katell, Mike and Briggs, Morgan},
  year = {2021},
  pages = {48},
  institution = {{Council of Europe}},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/Y3DCIZTZ/Leslie et al. - HUMAN RIGHTS, DEMOCRACY, AND THE RULE OF LAW.pdf}
}

@techreport{leslieUnderstandingArtificialIntelligence2019,
  title = {Understanding Artificial Intelligence Ethics and Safety: {{A}} Guide for the Responsible Design and Implementation of {{AI}} Systems in the Public Sector},
  shorttitle = {Understanding Artificial Intelligence Ethics and Safety},
  author = {Leslie, David},
  year = {2019},
  month = jun,
  institution = {{Zenodo}},
  doi = {10.5281/ZENODO.3240529},
  abstract = {A remarkable time of human promise has been ushered in by the convergence of the ever-expanding availability of big data, the soaring speed and stretch of cloud computing platforms, and the advancement of increasingly sophisticated machine learning algorithms. Innovations in AI are already leaving a mark on government, by improving the provision of essential social goods and services from healthcare, education, and transportation to food supply, energy, and environmental management. These bounties are likely just the start.  The prospect that progress in AI will help government to confront some of its most urgent challenges is exciting, but legitimate worries abound. As with any new and rapidly evolving technology, a steep learning curve means that mistakes and miscalculations will be made and that both unanticipated and harmful impacts will occur.  In order to manage these impacts responsibly and to direct the development of AI systems toward optimal public benefit, The Alan Turing Institute's public policy programme partnered with the Office for Artificial Intelligence and the Government Digital Service to produce guidance on the responsible design and implementation of AI systems in the public sector.  The guide, {$<$}em{$>$}Understanding Artificial Intelligence Ethics and Safety,{$<$}/em{$>$} is the most comprehensive guidance on the topic of AI ethics and safety in the public sector to date. It identifies the potential harms caused by AI systems and proposes concrete, operationalisable measures to counteract them. The guide stresses that public sector organisations can anticipate and prevent these potential harms by stewarding a culture of responsible innovation and by putting in place governance processes that support the design and implementation of ethical, fair, and safe AI systems. The guidance is relevant to everyone involved in the design, production, and deployment of a public sector AI project: from data scientists and data engineers to domain experts, delivery managers and departmental leads. Our aim -- and hope -- in writing the guide is to encourage civil servants interested in conducting AI projects to make considerations of AI ethics and safety a first priority.},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International, Open Access},
  langid = {english},
  keywords = {AI,Ethics,Government,Guidance,Public policy,Safety,The Alan Turing Institute},
  file = {/Users/cburr/Zotero/storage/52T7B452/Leslie - 2019 - Understanding artificial intelligence ethics and s.pdf}
}

@misc{manteleroArtificialIntelligenceData2019,
  title = {Artificial {{Intelligence}} and {{Data Protection}}: {{Challenges}} and {{Possible Remedies}}},
  author = {Mantelero, Alessandro},
  year = {2019},
  month = jan,
  file = {/Users/cburr/Zotero/storage/QFBWM5HN/T-PD(2018)09Rev_Mantelero_ReportAI_Final version_EN.pdf}
}

@techreport{mazzoliPRIORITISATIONUNCOVEREDDiscoverability2020,
  title = {{{PRIORITISATION UNCOVERED}}: {{The Discoverability}} of {{Public Interest Content Online}}},
  author = {Mazzoli, Eleonora Maria and Tambini, Damian},
  year = {2020},
  address = {{Strasbourg, France}},
  institution = {{Council of Europe Committee of Experts on Media Environment and Reform (MSI-REF)}},
  file = {/Users/cburr/Zotero/storage/JBJ3WRQQ/PUBLICATION Content Prioritisation Report.pdf}
}

@article{mcfaddenHarmonisingArtificialIntelligence2021,
  title = {Harmonising {{Artificial Intelligence}}:},
  author = {McFadden, Mark and Jones, Kate and Taylor, Emily and Osborn, Georgia},
  year = {2021},
  pages = {42},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/PI4B5KEE/McFadden et al. - Harmonising Artificial Intelligence.pdf}
}

@article{mcfaddenHarmonisingArtificialIntelligence2021a,
  title = {Harmonising {{Artificial Intelligence}}: The Role of Standards in the {{EU AI Regulation}}},
  author = {McFadden, Mark and Jones, Kate and Taylor, Emily and Osborn, Georgia},
  year = {2021},
  month = dec,
  pages = {42},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/LZXNTP8H/McFadden et al. - Harmonising Artificial Intelligence.pdf}
}

@misc{mijatovicHumanRightsComment2018,
  title = {Human {{Rights Comment}}. {{Safeguarding}} Human Rights in the Era of Artificial Intelligence.},
  author = {Mijatovi{\'c}, Dunja},
  year = {2018},
  month = jul,
  journal = {Commissioner for Human Rights},
  abstract = {The Council of Europe Commissioner for Human Rights - Human rights comments - Blog},
  howpublished = {https://www.coe.int/en/web/commissioner/blog/-/asset\_publisher/xZ32OPEoxOkq/content/safeguarding-human-rights-in-the-era-of-artificial-intelligence},
  langid = {british}
}

@misc{ministersdeputiesRecommendationCMRec2018,
  title = {Recommendation {{CM}}/{{Rec}}(2018)2 of the {{Committee}} of {{Ministers}} to Member {{States}} on the Roles and Responsibilities of Internet Intermediaries},
  author = {{Minister's Deputies}},
  year = {2018},
  month = mar,
  publisher = {{Council of Europe}},
  file = {/Users/cburr/Zotero/storage/EHIYX65T/CM_Rec(2018)2E.pdf}
}

@article{mokanderConformityAssessmentsPostmarket2021,
  title = {Conformity {{Assessments}} and {{Post-market Monitoring}}: {{A Guide}} to the {{Role}} of {{Auditing}} in the {{Proposed European AI Regulation}}},
  shorttitle = {Conformity {{Assessments}} and {{Post-market Monitoring}}},
  author = {M{\"o}kander, Jakob and Axente, Maria and Casolari, Federico and Floridi, Luciano},
  year = {2021},
  month = nov,
  journal = {Minds and Machines},
  issn = {0924-6495, 1572-8641},
  doi = {10.1007/s11023-021-09577-4},
  abstract = {The proposed European Artificial Intelligence Act (AIA) is the first attempt to elaborate a general legal framework for AI carried out by any major global economy. As such, the AIA is likely to become a point of reference in the larger discourse on how AI systems can (and should) be regulated. In this article, we describe and discuss the two primary enforcement mechanisms proposed in the AIA: the conformity assessments that providers of high-risk AI systems are expected to conduct, and the postmarket monitoring plans that providers must establish to document the performance of high-risk AI systems throughout their lifetimes. We argue that the AIA can be interpreted as a proposal to establish a Europe-wide ecosystem for conducting AI auditing, albeit in other words. Our analysis offers two main contributions. First, by describing the enforcement mechanisms included in the AIA in terminology borrowed from existing literature on AI auditing, we help providers of AI systems understand how they can prove adherence to the requirements set out in the AIA in practice. Second, by examining the AIA from an auditing perspective, we seek to provide transferable lessons from previous research about how to refine further the regulatory approach outlined in the AIA. We conclude by highlighting seven aspects of the AIA where amendments (or simply clarifications) would be helpful. These include, above all, the need to translate vague concepts into verifiable criteria and to strengthen the institutional safeguards concerning conformity assessments based on internal checks.},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/5JKTCZAK/Mökander et al. - 2021 - Conformity Assessments and Post-market Monitoring.pdf}
}

@misc{NationalDataStrategy2020,
  title = {National {{Data Strategy}}},
  year = {2020},
  journal = {GOV.UK},
  howpublished = {https://www.gov.uk/government/publications/uk-national-data-strategy/national-data-strategy},
  langid = {english}
}

@techreport{niklasSOCIALRIGHTSDATA2022,
  type = {Working {{Paper}}},
  title = {{{SOCIAL RIGHTS AND DATA TECHNOLOGIES}}: {{LOOKING FOR CONNECTIONS}}},
  author = {Niklas, J{\k{e}}drzej},
  year = {2022},
  institution = {{Data Justice Lab}}
}

@article{niklasWhatRightsMatter2021,
  title = {What Rights Matter? {{Examining}} the Place of Social Rights in the {{EU}}'s Artificial Intelligence Policy Debate},
  shorttitle = {What Rights Matter?},
  author = {Niklas, J{\k{e}}drzej and Dencik, Lina},
  year = {2021},
  month = sep,
  journal = {Internet Policy Review},
  volume = {10},
  number = {3},
  issn = {2197-6775},
  doi = {10.14763/2021.3.1579},
  abstract = {References to `European values' are often rooted in some perception of a commitment to particular rights that uphold certain principles about democracy and the relationship between state, market and citizens. Whilst rarely translated into consistent policy frameworks or activities, the formulation of new policy areas, such as artificial intelligence (AI), provide a window into what priorities, interests and concerns currently shape the European project. In this paper, we explore these questions in relation to the recent AI policy debate in the European Union with a particular focus on the place of social rights as a historically pertinent but neglected aspect of policy debates on technology. By examining submissions to the recent public consultation on the White Paper on AI Strategy, we argue that social rights occupy a marginal position in EU's policy debates on emerging technologies in favour of human rights issues such as individual privacy and nondiscrimination that are often translated into design solutions or procedural safeguards and a commitment to market creation. This is important as systems such as AI are playing an increasingly important role for questions of redistribution and economic inequality that relate to social rights. As such, the AI policy debate both exposes and advances new normative conflicts over the meaning of rights as a central component of any attachment to `European values'.},
  langid = {english},
  keywords = {social rights},
  file = {/Users/cburr/Zotero/storage/PYHP8LLN/Niklas and Dencik - 2021 - What rights matter Examining the place of social .pdf}
}

@misc{oecd.aipolicyobservatoryOECDFrameworkClassifying,
  title = {The {{OECD Framework}} for {{Classifying AI}} Systems},
  author = {{OECD.AI Policy Observatory}},
  file = {/Users/cburr/Zotero/storage/YA9HFINT/OECD.AI Policy Observatory_The OECD Framework for Classifying AI systems.pdf}
}

@misc{oecd2022,
  title = {The {{OECD Artificial Intelligence}} ({{AI}}) {{Principles}}},
  author = {OECD},
  year = {2022},
  abstract = {AI systems have become part of virtually every aspect of our daily lives with varying degrees of complexity, and the workplace and labour markets are no exception. If policy makers are to keep up, they must be able to understand AI systems. For that to happen, it is important to establish AI system classifications and taxonomies. In addition to coherent policies and regulatory approaches, AI classification will help to develop meaningful indicators and statistics. Any international or cross-sectoral comparisons will need a classification tool for accurate and like-for-like measures across policy areas. When it comes to the work force, these comparisons will be essential for monitoring AI diffusion and impact on labour and education.},
  howpublished = {https://oecd.ai/en/ai-principles},
  langid = {english},
  keywords = {AI system,AI system lifecycle},
  file = {/Users/cburr/Zotero/storage/K4NFNLJL/classification.html}
}

@misc{oecdOECDAISystems2021,
  title = {The {{OECD AI Systems Classification Framework}}},
  author = {OECD},
  year = {2021},
  month = feb,
  file = {/Users/cburr/Zotero/storage/RJ3KCP7L/7525_or_or60197aa03da70.mp4}
}

@techreport{oecdOECDDueDiligence2018,
  title = {{{OECD Due Diligence Guidance}} for {{Responsible Business Conduct}}},
  author = {OECD},
  year = {2018},
  institution = {{Organisation for Economic Cooperation and Development}},
  file = {/Users/cburr/Zotero/storage/U9IUJEXP/OECD-Due-Diligence-Guidance-for-Responsible-Business-Conduct.pdf}
}

@techreport{oecdOECDFRAMEWORKCLASSIFICATION2021,
  ids = {oecd2021c},
  title = {{{OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS}} \textendash{} {{PUBLIC CONSULTATION ON PRELIMINARY FINDINGS}}},
  author = {OECD},
  year = {2021},
  pages = {58},
  institution = {{Organisation for Economic Cooperation and Development}},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/JXJETHXQ/OECD_2021_OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS – PUBLIC CONSULTATION ON.pdf}
}

@misc{oecdOECDLegalInstruments2022,
  title = {{{OECD Legal Instruments}}: {{Recommendation}} of the {{Council}} on {{Artificial Intelligence}}},
  author = {OECD},
  year = {2022},
  file = {/Users/cburr/Zotero/storage/QLF45LSL/print.pdf}
}

@techreport{oecdScopingOECDAI2019,
  type = {{{OECD Digital Economy Papers}}},
  title = {Scoping the {{OECD AI}} Principles: {{Deliberations}} of the {{Expert Group}} on {{Artificial Intelligence}} at the {{OECD}} ({{AIGO}})},
  shorttitle = {Scoping the {{OECD AI}} Principles},
  author = {OECD},
  year = {2019},
  month = nov,
  series = {{{OECD Digital Economy Papers}}},
  volume = {291},
  number = {291},
  doi = {10.1787/d62f618a-en},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/8ZCCDAT5/2019 - Scoping the OECD AI principles Deliberations of t.pdf}
}

@techreport{officeforaiGuidelinesAIProcurement2020,
  title = {Guidelines for {{AI Procurement}}},
  author = {{Office for AI}},
  year = {2020},
  month = jun,
  address = {{London}},
  institution = {{Office for Artificial Intelligence}},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/XPVDM6KI/Guidelines_for_AI_procurement.pdf}
}

@misc{OutControlFailing,
  title = {Out of {{Control}}: {{Failing EU Laws}} for {{Digital Surveillance Export}}},
  shorttitle = {Out of {{Control}}},
  journal = {Amnesty International},
  abstract = {This report gives evidence of the gaps in the current European Union (EU) export regulation framework for digital surveillance technologies and provides the EU institutions and its member states with actionable recommendations to improve the protections of human rights in the upcoming Recast Dual Use Regulation. Amnesty International investigated the exports of digital surveillance technologies [\ldots ]},
  howpublished = {https://www.amnesty.org/en/documents/eur01/2556/2020/en/},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/B92CCGRT/en.html}
}

@misc{parliamentaryassemblyofthecouncilofeuropeDoc15147Braincomputer2020,
  title = {Doc. 15147 {{The}} Brain-Computer Interface: New Rights or New Threats to Fundamental Freedoms?},
  author = {{Parliamentary Assembly of the Council of Europe}},
  year = {2020},
  month = sep,
  file = {/Users/cburr/Zotero/storage/G4EGDNLW/doc. 15147.pdf}
}

@misc{parliamentaryassemblyofthecouncilofeuropeRecommendation210220172017,
  title = {Recommendation 2102 (2017) {{Technological}} Convergence, Artificial Intelligence and Human Rights},
  author = {{Parliamentary Assembly of the Council of Europe}},
  year = {2017},
  month = apr,
  publisher = {{Council of Europe}},
  file = {/Users/cburr/Zotero/storage/9GQ5ZRWW/pdf.pdf}
}

@misc{pdpcPDPCSingaporeApproach2020,
  title = {{{PDPC}} | {{Singapore}}'s {{Approach}} to {{AI Governance}}},
  author = {PDPC},
  year = {2020},
  abstract = {Singapore's Approach to AI Governance},
  howpublished = {https://www.pdpc.gov.sg/Help-and-Resources/2020/01/Model-AI-Governance-Framework},
  file = {/Users/cburr/Zotero/storage/SE62XBGL/SGModelAIGovFramework2.pdf;/Users/cburr/Zotero/storage/DV5CW4EM/Model-AI-Governance-Framework.html}
}

@article{penneyAdvancingHumanRightsbyDesignDualUse2018,
  title = {Advancing {{Human-Rights-by-Design}} in the {{Dual-Use Technology Industry}}},
  author = {Penney, Jonathon and McKune, Sarah and Gill, Lex and Deibert, Ronald J.},
  year = {Spring/Summer 2018},
  journal = {Journal of International Affairs},
  volume = {71},
  number = {2},
  pages = {103--110},
  publisher = {{Journal of International Affairs}},
  address = {{New York, United States}},
  issn = {0022197X},
  abstract = {Citizen Lab research has repeatedly exposed the ways in which deep packet inspection (DPI) technology and Internet filtering software-services offered by technology companies like Sandvine and Netsweeper-can be used to censor speech and threaten freedom of expression online.5 Research has also revealed the widespread abuse of dual-use technology in the form of malicious software, spyware, and hacking tools (like those developed by private sector security and intelligence firms, including FinFisher, Hacking Team, and NSO Group) governments with problematic human rights records use to target civil society.6 As surveillance technology is propagated and normalized, it has crept into ordinary commercial markets, putting tools or techniques designed for use by intelligence and law enforcement into the hands of ordinary criminal actors and abusive spouses alike.7 These business practices would not be possible without private sector financial and investment firms bankrolling them. [...]Francisco Partners is a global private equity firm specialized in the technology sector.8 Its portfolio companies have included Blue Coat (since acquired by Symantec), a manufacturer of dual-use technology deployed in countries with deeply problematic human rights records including Iran, Syria, and Sudan, subject to sanctions by the United States government.9 Sandvine-a company whose PacketLogic devices were apparently used to surreptitiously inject malicious and dubious redirects for users in Turkey, Syria, and Egypt-is currently a member of the Francisco Partners family.10 And Francisco Partners has long been the controlling shareholder in an Israeli cyber-arms dealer called NSO Group.11 The NSO Group spyware can be directly linked to the illegal surveillance of human rights activists, journalists, and lawyers from the UAE to Mexico.1213 Emerging markets for the sale of filtering, hacking, and targeted surveil- lance technologies, especially to repressive and authoritarian states, raise serious human rights concerns. International human rights law, at present, does not explicitly require states to police business activities outside their national jurisdiction; however, states do have a general duty to ensure that businesses over which they have jurisdiction respect human rights.17 In Citizen Lab's Planet Netsweeper report, researchers set out a range of concrete recommendations based on these obligations.18 For national governments, particularly those such as the Canadian government that have funded and supported dual-use technology companies, the report recommends tying the ability to receive financial support (such as research and development grants) to clear prohibitions on illegal and unethical business practices abroad.19 It also recommends restricting government procurement of dual-use technology to companies with clean human rights records; mandating stronger corporate transparency; and empowering agencies tasked with investigating Canadian businesses involved in human rights abuses abroad. In the spring of 2018, for example, over 4,000 Google employees signed a letter condemning the company's involvement with Project Maven, a U.S. military effort to combine machine learning and drone surveillance.24 As a result of their advocacy, the Pentagon contract will not be renewed-and Google has now adopted a series of principles to govern the company's research and development activities in the field of artificial intelligence.25 The list of principles also includes an explicit list of "applications we will not pursue," restricting the development of weapons, mass surveillance tools, and other "technologies whose purpose contravenes widely accepted principles of international law and human rights.},
  copyright = {Copyright Journal of International Affairs Spring/Summer 2018},
  langid = {english},
  keywords = {Censorship,Employees,Freedom of speech,Human rights,International law,Malware,Political Science--International Relations,Privacy,Right of privacy,Social responsibility,Surveillance,Web sites},
  file = {/Users/cburr/Zotero/storage/RN34WZ5N/Penney et al. - 2018 - Advancing Human-Rights-by-Design in the Dual-Use T.pdf}
}

@misc{ProposalREGULATIONEUROPEAN2021,
  title = {Proposal for a {{REGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL LAYING DOWN HARMONISED RULES ON ARTIFICIAL INTELLIGENCE}} ({{ARTIFICIAL INTELLIGENCE ACT}}) {{AND AMENDING CERTAIN UNION LEGISLATIVE ACTS}}},
  year = {2021},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/6RRYR5QH/HTML.html}
}

@book{radley-gardnerREGULATIONEU20212021,
  title = {{{REGULATION}} ({{EU}}) 2021/821: {{Recast Dual-Use Regulation}}},
  editor = {{Radley-Gardner}, Oliver and Beale, Hugh and Zimmermann, Reinhard},
  year = {2021},
  publisher = {{Hart Publishing}},
  doi = {10.5040/9781782258674},
  isbn = {978-1-78225-864-3 978-1-78225-865-0 978-1-78225-866-7 978-1-78225-867-4},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/B4EJXXNL/Radley-Gardner et al. - 2016 - Fundamental Texts On European Private Law.pdf}
}

@misc{RecastEUDualUse2021,
  title = {Recast {{EU Dual-Use Regulation}} to Come into Force on 9 {{September}} 2021 - Our Summary and How to Receive Full Analysis},
  year = {2021},
  month = jun,
  journal = {Sanctions \& Export Controls Update},
  abstract = {On 11 June 2021, the Recast Dual-Use Regulation was published in the Official Journal of the European Union as Regulation 2021/821 (the ``Regulation''). The Regulation, which comes into force on 9 September 2021, will replace the current Dual-Use Regulation introduced in 2009. Key changes include: Two new general export authorisations: The Regulation introduces a general},
  howpublished = {https://sanctionsnews.bakermckenzie.com/recast-eu-dual-use-regulation-to-come-into-force-on-9-september-2021-our-summary-and-how-to-receive-full-analysis/},
  langid = {american},
  file = {/Users/cburr/Zotero/storage/IKTVC4AJ/recast-eu-dual-use-regulation-to-come-into-force-on-9-september-2021-our-summary-and-how-to-rec.html}
}

@misc{reinholdAlgorithmWatchResponseEuropean2021,
  title = {{{AlgorithmWatch}}'s Response to the {{European Commission}}'s Proposed Regulation on {{Artificial Intelligence}} \textendash{} {{A}} Major Step with Major Gaps},
  author = {Reinhold, Friederike},
  year = {2021},
  month = apr,
  journal = {Algorithm Watch},
  collaborator = {M{\"u}ller, Angela},
  howpublished = {https://algorithmwatch.org/en/response-to-eu-ai-regulation-proposal-2021/}
}

@article{rpssubmitterAIRegulationEntering2021,
  title = {The {{AI Regulation}}: Entering an {{AI}} Regulatory Winter? {{Why}} an Ad Hoc Directive on {{AI}} in Employment Is Required},
  shorttitle = {The {{AI Regulation}}},
  author = {RPS Submitter, European Trade Union Institute and {Ponce del Castillo}, Aida},
  year = {2021},
  journal = {SSRN Electronic Journal},
  issn = {1556-5068},
  doi = {10.2139/ssrn.3873786},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/AZ427HP5/RPS Submitter and Ponce del Castillo - 2021 - The AI Regulation entering an AI regulatory winte.pdf}
}

@book{russellArtificialIntelligenceModern2016,
  title = {Artificial Intelligence: A Modern Approach. {{Malaysia}}},
  author = {Russell, Stuart J. and Norvig, Peter},
  year = {2016},
  publisher = {{Pearson Education Limited London, UK:}}
}

@misc{scappucciProtectionChildrenSexual2017,
  title = {The Protection of Children against Sexual Exploitation and Sexual Abuse Facilitated by Information and Communication Technologies ({{ICTs}})},
  author = {Scappucci, Gioia},
  year = {2017}
}

@article{schulzke2019,
  title = {Drone {{Proliferation}} and the {{Challenge}} of {{Regulating Dual-Use Technologies}}},
  author = {Schulzke, Marcus},
  year = {2019},
  month = sep,
  journal = {International Studies Review},
  volume = {21},
  number = {3},
  pages = {497--517},
  issn = {1521-9488},
  doi = {10.1093/isr/viy047},
  abstract = {The controversy surrounding military drones has generated many proposals for restricting or prohibiting existing drones, additional autonomous variants that may be created in the future, and the sale of drones to certain markets. Moreover, there is broad interest in regulating military drones, with proposals coming not only from academics but also from NGOs and policymakers. I argue that these proposals generally fail to consider the dual-use character of drones and that they therefore provide inadequate regulatory guidance. Drones are not confined to the military but rather spread across international and domestic security roles, humanitarian relief efforts, and dozens of civilian applications. Drones, their component technologies, the control infrastructure, and the relevant technical expertise would continue to develop under a military-focused regulatory regime as civilian technologies that have the potential to be militarized. I evaluate the prospects of drone regulation with the help of research on other dual-use technologies, while also showing what the study of drones can contribute to that literature. Drones' ubiquity in nonmilitary roles presents special regulatory challenges beyond those associated with WMDs and missiles, which indicates that strict regulatory controls or international governance frameworks are unlikely to succeed. With this in mind, I further argue that future research should acknowledge that drone proliferation across military and civilian spheres is unavoidable and shift focus to considering how drone warfare may be moderated by countermeasures and institutional pressures.},
  file = {/Users/cburr/Zotero/storage/AGP92AFP/Schulzke - 2019 - Drone Proliferation and the Challenge of Regulatin.pdf;/Users/cburr/Zotero/storage/8SNS858B/4999288.html}
}

@article{smuhaIndividualGoverningAI2021,
  title = {Beyond the Individual: Governing {{AI}}'s Societal Harm},
  shorttitle = {Beyond the Individual},
  author = {Smuha, Nathalie A.},
  year = {2021},
  month = sep,
  journal = {Internet Policy Review},
  volume = {10},
  number = {3},
  issn = {2197-6775},
  doi = {10.14763/2021.3.1574},
  abstract = {In this paper, I distinguish three types of harm that can arise in the context of artificial intelligence (AI): individual harm, collective harm and societal harm. Societal harm is often overlooked, yet not reducible to the two former types of harm. Moreover, mechanisms to tackle individual and collective harm raised by AI are not always suitable to counter societal harm. As a result, policymakers' gap analysis of the current legal framework for AI not only risks being incomplete, but proposals for new legislation to bridge these gaps may also inadequately protect societal interests that are adversely impacted by AI. By conceptualising AI's societal harm, I argue that a shift in perspective is needed beyond the individual, towards a regulatory approach of AI that addresses its effects on society at large. Drawing on a legal domain specifically aimed at protecting a societal interest\textemdash environmental law\textemdash I identify three `societal' mechanisms that EU policymakers should consider in the context of AI. These concern (1) public oversight mechanisms to increase accountability, including mandatory impact assessments with the opportunity to provide societal feedback; (2) public monitoring mechanisms to ensure independent information gathering and dissemination about AI's societal impact; and (3) the introduction of procedural rights with a societal dimension, including a right to access to information, access to justice, and participation in public decision-making on AI, regardless of the demonstration of individual harm. Finally, I consider to what extent the European Commission's new proposal for an AI regulation takes these mechanisms into consideration, before offering concluding remarks.},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/VE2JH95G/Smuha - 2021 - Beyond the individual governing AI’s societal har.pdf}
}

@article{tabassi2022,
  title = {{{AI Risk Management Framework}}: {{Second Draft}} - {{August}} 18, 2022},
  author = {Tabassi, Elham (Fed)},
  year = {2022},
  pages = {36},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/EGRYNERL/Tabassi - 2022 - AI Risk Management Framework Second Draft - Augus.pdf}
}

@techreport{thedanishinstituteforhumanrightsHumanRightsImpact2020,
  title = {Human Rights Impact Assessment of Digital Activities},
  author = {{The Danish Institute for Human Rights}},
  year = {2020},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/63EHEPHZ/Phase 5_Reporting and Evaluation_ENG_accessbile.pdf;/Users/cburr/Zotero/storage/724HP3M9/Cross-cutting_ Stakeholder Engagement_ENG_accessible.pdf;/Users/cburr/Zotero/storage/GSHD7VUV/Phase 2_Data Collection and Context Analysis_ENG_accessible.pdf;/Users/cburr/Zotero/storage/K8NPNVXA/Phase 1_Planning and Scoping_ENG_accessible.pdf;/Users/cburr/Zotero/storage/M7IM98HX/Phase 3_ Analysing Impacts_ENG_accessible.pdf;/Users/cburr/Zotero/storage/Y24LRQRB/Phase 4_ Impact prevention mitigation and remediation_ENG_accessible.pdf;/Users/cburr/Zotero/storage/Z8ZIZAN3/The Danish Institute for Human Rights_Human rights impact assessment of digital activities.pdf;/Users/cburr/Zotero/storage/55NWQI4C/human-rights-impact-assessment-digital-activities.html}
}

@article{theodorouEthicalSociolegalGovernance2020,
  title = {Towards Ethical and Socio-Legal Governance in {{AI}}},
  author = {Theodorou, Andreas and Dignum, Virginia},
  year = {2020},
  month = jan,
  journal = {Nature Machine Intelligence},
  volume = {2},
  number = {1},
  pages = {10--12},
  issn = {2522-5839},
  doi = {10.1038/s42256-019-0136-y},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/WDZTEL4R/Theodorou and Dignum - 2020 - Towards ethical and socio-legal governance in AI.pdf}
}

@article{thomasSelfdrivingCarUsers2022,
  title = {Self-Driving Car Users Could Watch Films on Motorway under New {{DfT}} Proposals},
  author = {Thomas, Tobi},
  year = {2022},
  month = apr,
  journal = {The Guardian},
  issn = {0261-3077},
  abstract = {Proposed interim measures include making insurance companies liable for accidents in self-driving vehicles},
  chapter = {Technology},
  langid = {british},
  keywords = {Oscars 2019,Self-driving cars,Technology,Transport,Transport policy,UK news}
}

@techreport{unescoDRAFTTEXTRECOMMENDATION2021,
  title = {{{DRAFT TEXT OF THE RECOMMENDATION ON THE ETHICS OF ARTIFICIAL INTELLIGENCE}}},
  author = {UNESCO},
  year = {2021},
  number = {Report of the Social and Human Sciences Commission (SHS)},
  pages = {39},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/NLGYU4H4/DCPMS_U2104174.docx}
}

@article{urquhartPolicingFacesPresent2021,
  title = {Policing Faces: The Present and Future of Intelligent Facial Surveillance},
  shorttitle = {Policing Faces},
  author = {Urquhart, Lachlan and Miranda, Diana},
  year = {2021},
  month = oct,
  journal = {Information \& Communications Technology Law},
  volume = {0},
  number = {0},
  pages = {1--26},
  publisher = {{Routledge}},
  issn = {1360-0834},
  doi = {10.1080/13600834.2021.1994220},
  abstract = {In this paper, we discuss the present and future uses of intelligent facial surveillance (IFS) in law enforcement. We present an empirical and legally focused case study of live automated facial recognition technologies (LFR) in British policing. In Part I, we analyse insights from 26 frontline police officers exploring their concerns and current scepticism about LFR. We analyse recent UK case law on LFR use by police which raises concerns around human rights, data protection and anti-discrimination laws. In Part II, we consider frontline officers' optimism around future uses of LFR and explore emerging forms of IFS, namely emotional AI (EAI) technologies. A key novelty of the paper is our analysis on how the proposed EU AI Regulation (AIR) will shape future uses of IFS in policing. AIR makes LFR a prohibited form of AI and EAI use by law enforcement will be regulated as high-risk AI that has to comply with new rules and design requirements. Part III presents a series of 10 practical lessons, drawn from our reflections on the legal and empirical perspectives. These aim to inform any future law enforcement use of IFS in the UK and beyond.},
  keywords = {Emotional AI,Facial recognition,law,policing,surveillance},
  annotation = {\_eprint: https://doi.org/10.1080/13600834.2021.1994220},
  file = {/Users/cburr/Zotero/storage/M4SNGVI7/Urquhart and Miranda - 2021 - Policing faces the present and future of intellig.pdf;/Users/cburr/Zotero/storage/J43KE5M7/13600834.2021.html}
}

@article{vanestHumanRightsRobot2017,
  title = {Human Rights in the Robot Age: {{Challenges}} Arising from the Use of Robotics, Artificial Intelligence, and Virtual and Augmented Reality \textendash{} {{Expert}} Report Written for the {{Committee}} on {{Culture}}, {{Science}}, {{Education}} and {{Media}} of the {{Parliamentary Assembly}} of the {{Council}} of {{Europe}} ({{PACE}})},
  author = {{van Est}, Rinie and Gerritsen, Joost},
  year = {2017},
  pages = {58},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/A5FTJKL6/Messer - Human Rights in the Robot Age.pdf}
}

@article{vealeDemystifyingDraftEU2021,
  title = {Demystifying the {{Draft EU Artificial Intelligence Act}}},
  author = {Veale, Michael and Zuiderveen Borgesius, Frederik},
  year = {2021},
  journal = {Computer Law Review International},
  volume = {22},
  number = {4},
  pages = {97--112},
  doi = {10.9785/cri-2021-220402},
  abstract = {In April 2021, the European Commission proposed a Regulation on Artificial Intelligence, known as the AI Act. We present an overview of the Act and analyse its implications, drawing on scholarship ranging from the study of contemporary AI practices to the structure of EU product safety regimes over the last four decades. Aspects of the AI Act, such as different rules for different risk-levels of AI, make sense. But we also find that some provisions of the draft AI Act have surprising legal implications, whilst others may be largely ineffective at achieving their stated goals. Several overarching aspects, including the enforcement regime and the effect of maximum harmonisation on the space for AI policy more generally, engender significant concern. These issues should be addressed as a priority in the legislative process.},
  file = {/Users/cburr/Zotero/storage/6NPWHM56/Veale and Zuiderveen Borgesius - 2021 - Demystifying the Draft EU Artificial Intelligence .pdf}
}

@article{wagnerWhosePoliticsWhose2021,
  title = {Whose {{Politics}}? {{Whose Rights}}? {{Transparency}}, {{Capture}} and {{Dual-Use Export Controls}}},
  shorttitle = {Whose {{Politics}}?},
  author = {Wagner, Ben},
  year = {2021},
  month = mar,
  journal = {Security and Human Rights},
  volume = {31},
  number = {1-4},
  pages = {35--46},
  publisher = {{Brill Nijhoff}},
  issn = {1875-0230, 1874-7337},
  doi = {10.1163/18750230-31010006},
  abstract = {Abstract What kinds of politics do export controls entail and whose rights do they enable? The following article will take a critical perspective on the governance challenges associated with export controls of dual-use technologies. After discussing challenges around transparency, the performance of human rights and export control havens, this article will then turn to looking at policy solutions, including audits, transparency and targeted international governance mechanisms. With conclusion, export controls continue to constitute an important policy tool to promote human rights and can be improved considerably to strengthen human rights further.},
  langid = {english},
  keywords = {digital technology,dual-use,export control,human rights,transparency},
  file = {/Users/cburr/Zotero/storage/JPBXVAAM/Wagner - 2021 - Whose Politics Whose Rights Transparency, Captur.pdf}
}

@misc{wardleDGI2017092017,
  title = {{{DGI}}(2017)09 {{Information Disorder}}: {{Toward}} an Interdisciplinary Framework for Research and Policy Making},
  author = {Wardle, Claire and Derakhshan, Hossein},
  year = {2017}
}

@article{whangTradeEmergingTechnologies2021,
  title = {Trade and {{Emerging Technologies}}: {{A Comparative Analysis}} of the {{United States}} and the {{European Union Dual-Use Export Control Regulations}}},
  shorttitle = {Trade and {{Emerging Technologies}}},
  author = {Whang, Cindy},
  year = {2021},
  month = mar,
  journal = {Security and Human Rights},
  volume = {31},
  number = {1-4},
  pages = {11--34},
  publisher = {{Brill Nijhoff}},
  issn = {1875-0230, 1874-7337},
  doi = {10.1163/18750230-31010007},
  abstract = {Abstract Export controls are domestic trade restrictions placed on technologies that have been determined to be important to the national security concerns of a country. In recent years, the policy purpose for maintaining export control regulations have shifted, and how these new export control regulations would interact with new emerging technologies is something that should be analyzed and considered. The passage of the United States (US) Export Control Reform Act (ecra) of 2018 and the proposed regulatory changes for the European Union's (EU) Council Regulation (ec) No. 428/2009 have shifted the focus of dual-use export controls so that the national security goals of these controls have broadened to include economic security and human rights concerns. This paper argues that the infusion of geoeconomics into US national security considerations and the proposed expansion to include human rights considerations into EU export control regulations are made mutually exclusive of each other and were not made to expand the reach of export controls in a unifying way. Rather, the purpose and structural change to export control regulations serves to create more regulatory barriers on the trade of emerging technology industries that would not only impact the US and the EU, but also their international trading partners.},
  langid = {english},
  keywords = {dual-use export control,emerging technologies,human rights,national security,regulatory barriers},
  file = {/Users/cburr/Zotero/storage/F47V3HCI/Whang - 2021 - Trade and Emerging Technologies A Comparative Ana.pdf}
}

@misc{wingfieldCAHAIProposedElements2022,
  title = {{{CAHAI}}'{{S}} Proposed Elements of a Legal Framework on {{AI}}: Our Thoughts | {{Global Partners Digital}}},
  shorttitle = {{{CAHAI}}'{{S}} Proposed Elements of a Legal Framework on {{AI}}},
  author = {Wingfield, Richard},
  year = {2022},
  month = mar,
  abstract = {Global Partners Digital},
  langid = {american},
  file = {/Users/cburr/Zotero/storage/B9FFSL6Y/cahais-proposed-elements-of-a-legal-framework-on-ai-our-thoughts.html}
}

@misc{workinggrouponaiandcriminallawCDPC20203Rev2020,
  title = {{{CDPC}}(2020){{3Rev}}: {{European Committee}} on {{Crime Problems}} ({{CDPC}})},
  author = {{Working Group on AI {and} Criminal Law}},
  year = {2020},
  publisher = {{Council of Europe}},
  file = {/Users/cburr/Zotero/storage/EKNKSFXC/CDPC(2020)3 - Feasibility Study of a Future Instrument on AI and Criminal Law_Rev August_04092020_EN_clean.docx.pdf}
}

@misc{yeungDGI2019052019,
  title = {{{DGI}}(2019)05. {{A}} Study of the Implications of Advanced Digital Technologies (Including {{AI}} Systems) for the Concept of Responsibility within a Human Rights Framework},
  author = {Yeung, Karen},
  year = {2019},
  publisher = {{Council of Europe}},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/UY2VVVCB/Yeung - 2019 - A study of the implications of advanced digital te.pdf}
}


